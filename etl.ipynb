{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eadf557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import datetime\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2ada5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "logfile =\"logfile.txt\"\n",
    "all_dim=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84936cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract():\n",
    "    url=\"FakeNamesUK1.csv\"\n",
    "    data=pd.read_csv(url, low_memory=False)\n",
    "    print(f\"{len(data)} will be extracted and loaded and transformed\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c4bb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def transform(datas):\n",
    "\n",
    "    \n",
    "\n",
    "    df=datas[['Number','Gender','Title','Name','Name.1', 'Address','ZipCode','EmailAddress','Username','Password',\n",
    "                'CCType','CCNumber','CVV2','CCExpires','BloodType','Kilograms','Centimeters']]\n",
    "    df = df.copy()\n",
    "    df = df.rename({\"Number\":\"ID\", \"Name.1\":\"LastName\", \"Name\":\"FirstName\"}, axis=\"columns\")\n",
    "\n",
    "    #selecting valid records only\n",
    "    df = df[pd.to_numeric(df[\"Kilograms\"], errors=\"coerce\").notna()]\n",
    "    df = df[pd.to_numeric(df[\"Centimeters\"], errors=\"coerce\").notna()]\n",
    "\n",
    "    #dropping empty ID and convertin to integer\n",
    "    df = df.dropna(subset=[\"ID\"])\n",
    "    df[\"ID\"] = df[\"ID\"].astype(int)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    df.loc[:, \"BMI\"] = round(pd.to_numeric(df[\"Kilograms\"], errors=\"coerce\") /\n",
    "                         (pd.to_numeric(df[\"Centimeters\"], errors=\"coerce\")**2), 2)\n",
    "\n",
    "\n",
    "\n",
    "    df['BMI'] = round(pd.to_numeric(df['Kilograms'], errors='coerce') / \n",
    "                    pd.to_numeric(df['Centimeters'], errors='coerce') / \n",
    "                    pd.to_numeric(df['Centimeters'], errors='coerce') * 10000, 2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    conditions = [\n",
    "    df['BMI'].lt(18.5),\n",
    "    df['BMI'].le(24.9),\n",
    "    df['BMI'].le(29.9)\n",
    "    ]\n",
    "\n",
    "    choices = ['Underweight', 'Healthy', 'Overweight']\n",
    "\n",
    "\n",
    "    df['BodyType'] = np.select(conditions, choices, default='Obese')\n",
    "\n",
    "    #creating dimensions for analysis\n",
    "    persons=df[['ID','FirstName','LastName','Gender']]\n",
    "\n",
    "    medicals = df[['BloodType','Kilograms','Centimeters','BMI','BodyType','ID']]\n",
    "\n",
    "    all_dim=[persons, medicals]\n",
    "\n",
    "    print(f\"{len(df)} records normalised into {len(all_dim)} tables and will be loaded into the data warehouse\")\n",
    "\n",
    "    return persons,medicals\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd790a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7549d0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Connect to postgres system DB\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"postgres\",\n",
    "    password=\"chika\",\n",
    "    dbname=\"postgres\"  # default DB, not the one we are dropping\n",
    ")\n",
    "\n",
    "conn.autocommit = True\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Terminate other connections to target DB\n",
    "cur.execute(\"\"\"\n",
    "    SELECT pg_terminate_backend(pid)\n",
    "    FROM pg_stat_activity\n",
    "    WHERE datname = 'my_etl_db'\n",
    "    AND pid <> pg_backend_pid();\n",
    "\"\"\")\n",
    "\n",
    "# Drop and recreate DB\n",
    "cur.execute(\"DROP DATABASE IF EXISTS my_etl_db;\")\n",
    "cur.execute(\"CREATE DATABASE my_etl_db;\")\n",
    "cur.close()\n",
    "conn.close()\n",
    "\n",
    "# Reconnect to the new DB\n",
    "conn = psycopg2.connect(\n",
    "    host=\"localhost\",\n",
    "    user=\"postgres\",\n",
    "    password=\"chika\",\n",
    "    dbname=\"my_etl_db\"\n",
    ")\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Persons table\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS persons (\n",
    "    PID INT PRIMARY KEY,\n",
    "    FirstName VARCHAR(100),\n",
    "    LastName VARCHAR(100),\n",
    "    Gender VARCHAR(10)    \n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "# Medicals table\n",
    "cur.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS medicals (\n",
    "    ID SERIAL PRIMARY KEY,\n",
    "    BloodType VARCHAR(5),\n",
    "    Kilograms DOUBLE PRECISION,  -- better than VARCHAR\n",
    "    Centimeters DOUBLE PRECISION,\n",
    "    BMI DOUBLE PRECISION,\n",
    "    BodyType VARCHAR(50),\n",
    "    PID INT,\n",
    "    FOREIGN KEY(PID) REFERENCES persons(PID)\n",
    ");\n",
    "\"\"\")\n",
    "\n",
    "conn.commit()\n",
    "\"\"\" cur.close()\n",
    "conn.close() \"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e10ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_person(csv_person):\n",
    "    cursor=conn.cursor()\n",
    "    with open (csv_person,'r') as file:\n",
    "        reader=csv.reader(file)\n",
    "        next(reader)\n",
    "        for row in reader:\n",
    "            cursor.execute(\"INSERT INTO persons VALUES (%s, %s, %s, %s)\", row)\n",
    "        conn.commit()\n",
    "        print (f\"{(csv_person)} was loaded succesfully into the Data warehouse\")\n",
    "        cursor.close()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "def load_medicals(csv_medicals):\n",
    "    cursor = conn.cursor()\n",
    "    with open(csv_medicals, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # skip header\n",
    "        for row in reader:\n",
    "            cursor.execute(\"INSERT INTO medicals (BloodType, Kilograms, Centimeters, BMI, BodyType, PID) VALUES (%s, %s, %s, %s, %s, %s)\", row)\n",
    "    conn.commit()\n",
    "    cursor.close()\n",
    "    print (f\"{(csv_medicals)} was loaded succesfully into the Data warehouse\")\n",
    "    print (\"Done....\")\n",
    "    conn.close()\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf599807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(datasets, filenames):\n",
    "    for df, filename in zip(datasets,filenames):\n",
    "        df.to_csv(filename, index=False)\n",
    "        \n",
    "        print(f\"{(filename)} table was staged ready to be loaded into the data warehouse\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf599807",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Log function to write to a text file the processes\n",
    "def log(message):\n",
    " timestamp_format = '%Y-%h-%d-%H:%M:%S' #Year-Monthname-Day-Hour-Minute-Second\n",
    " now = datetime.now()\n",
    " timestamp = now.strftime(timestamp_format)\n",
    " with open(\"logfile.txt\",\"a\") as f:\n",
    "     f.write(timestamp + ',' + message + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8bfaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Start ETL\n",
    "log(\"ETL STARTED\")\n",
    "\n",
    "log(\"Extract phase Started\")\n",
    "datas=extract()\n",
    "log(\"Extract phase Ended\")\n",
    "\n",
    "\n",
    "log(\"Transform phase Started\")\n",
    "datasets = transform(datas)\n",
    "load(datasets,[\"persons.csv\", \"medicals.csv\"])\n",
    "log(\"Transform phase Ended\")\n",
    "\n",
    "\n",
    "log(\"Load phase Started\")\n",
    "csv_person=\"persons.csv\"\n",
    "load_person(csv_person)\n",
    "\n",
    "#csv_contacts=\"contacts.csv\"\n",
    "#load_contacts(csv_contacts)\n",
    "\n",
    "csv_medicals=\"medicals.csv\"\n",
    "load_medicals(csv_medicals)\n",
    "\n",
    "#csv_payments=\"payments.csv\"\n",
    "#load_payments(csv_payments)\n",
    "log(\"Load phase Ended\")\n",
    "\n",
    "log(\"ETL Job Ended\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33603178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
